{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMv7whAExzjryjGEM4EoAnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/batoolkhanfar01/LogisticRegression/blob/main/logisticregression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "0JxNAVj-L3DE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Logistic_Regression():\n",
        "\n",
        "  def __init__(self,learning_rate, n_epochs, mini_batch, threshold ): \n",
        "    self.learning_rate = learning_rate\n",
        "    self.n_epochs = n_epochs \n",
        "    self.mini_batch = mini_batch\n",
        "    self.threshold = threshold\n",
        "  \n",
        "  def fit(self, X, Y):\n",
        "     \n",
        "      self.m, self.n = X.shape\n",
        "      self.w = np.zeros(self.n)\n",
        "      self.b = 0\n",
        "      self.X =  X\n",
        "      self.Y = Y\n",
        "\n",
        "  def sigmoid(self, z):\n",
        "    Y_hat = 1/(1+np.exp(-z))\n",
        "    return Y_hat\n",
        "\n",
        "  def weight (self):\n",
        "    return np.random.rand(3, 1)\n",
        "\n",
        "  def data(self,x ,y):\n",
        "    x = np.c_[np.ones((self.m, 1)), self.X]\n",
        "    y =  self.Y.reshape(100,1)\n",
        "    return x , y \n",
        "  def learning_schedule(t):\n",
        "     t0, t1 = 5, 50 \n",
        "     return t0 / (t + t1)\n",
        "  def list(self):\n",
        "    weight_path_sgd = []\n",
        "    return weight_path_sgd\n",
        "     \n",
        "\n",
        "#Gradeint Descent\n",
        "  def gradeint(self, x, y):\n",
        "    for epochs in range(self.n_epochs):\n",
        "        gradeint = 1/self.m * x.T.dot(self.sigmoid(x.dot(self.weight))- y)\n",
        "        weight = weight - self.learning_rate * gradeint\n",
        "#Stochastic\n",
        "  def stochastic(self, x, y):\n",
        "    for epochs in range(self.n_epochs):\n",
        "     for i in range(self.m):\n",
        "       random_index = np.random.randint(self.m)            \n",
        "       xi = x[random_index:random_index+1]           \n",
        "       yi = y[random_index:random_index+1]      \n",
        "       gradeint = 2 * xi.T.dot(self.sigmoid(xi.dot(self.weight) - yi))     \n",
        "       eta = self.learning_schedule(epochs * self.m + i)\n",
        "    weight = self.weight - eta * gradeint\n",
        "    self.list.append(weight)\n",
        "\n",
        "#Mini-Batch\n",
        "  def Mini(self, x, y):\n",
        "    for epochs in range (self.n_epochs):\n",
        "      shuffled_indices = np.random.permutation(self.m)\n",
        "      X_shuffled = x[shuffled_indices]\n",
        "      y_shuffled = y[shuffled_indices]\n",
        "      for i in range (0, self.m, self.mini_batch):\n",
        "        xi = X_shuffled[i:i+self.mini_batch]\n",
        "        yi = y_shuffled[i:i+self.mini_batch]\n",
        "        gradients = 2/self.mini_batch * xi.T.dot(self.sigmoid(xi.dot(self.weight) - yi))\n",
        "        weight = self.weight - self.learning_schedule * gradients\n",
        "        self.list.append(weight)\n",
        "     \n",
        "  def predict(self, X):\n",
        "     y_pred = np.where(self.sigmoid(z=5) > self.threshold , 1, 0 )\n",
        "     return y_pred\n",
        "  \n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1)\n",
        "from sklearn.model_selection import train_test_split  \n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1)\n",
        "\n",
        "def standardize(X_train):\n",
        "    for i in range((X_train)[1]):\n",
        "        X_train[:,i] = (X_train[:,i] - np.mean(X_train[:,i]))/np.std(X_train[:,i])\n",
        "def F1_score(y, Y_hat ):\n",
        "    tp,tn,fp,fn = 0,0,0,0\n",
        "    for i in range(len(y)):\n",
        "        if y[i] == 1 and Y_hat[i] == 1:\n",
        "            tp += 1\n",
        "        elif y[i] == 1 and Y_hat[i] == 0:\n",
        "            fn += 1\n",
        "        elif y[i] == 0 and Y_hat[i] == 1:\n",
        "            fp += 1\n",
        "        elif y[i] == 0 and Y_hat[i] == 0:\n",
        "            tn += 1\n",
        "    precision = tp/(tp+fp)\n",
        "    recall = tp/(tp+fn)\n",
        "    f1_score = 2*precision*recall/(precision+recall)\n",
        "    return f1_score    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Log = Logistic_Regression(0.01, 1000, 20, 0.2)\n",
        "model= Log.fit(X_train,y_train)\n",
        "y_pred = Log.predict(X_test)\n",
        "#y_train2 = Log.predict(X_train)\n",
        "\n",
        "#f1_score_tr = F1_score(y_train,y_train2)\n",
        "f1_score_te = F1_score(y_test,y_pred)\n",
        "#print(f1_score_tr)\n",
        "print(f1_score_te)\n"
      ],
      "metadata": {
        "id": "OqHei3mBWQ6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "model = LogisticRegression().fit(X_train,y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f1_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvTrSsmnQ2iy",
        "outputId": "b35a8d7a-2f61-4855-8cc5-010a15f61da5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9090909090909091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "chIpfFoVWDCg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}